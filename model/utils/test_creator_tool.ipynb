{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/disk1/home/yupeng/EndOfSep/FusionNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "\n",
    "from model.utils.bbox_tools import bbox2loc, bbox_iou, loc2bbox\n",
    "from model.utils.nms.non_maximum_suppression import non_maximum_suppression\n",
    "\n",
    "\n",
    "class ProposalTargetCreator(object):\n",
    "    \"\"\"Assign ground truth bounding boxes to given RoIs.\n",
    "    The :meth:`__call__` of this class generates training targets\n",
    "    for each object proposal.\n",
    "    This is used to train Faster RCNN [#]_.\n",
    "    .. [#] Shaoqing Ren, Kaiming He, Ross Girshick, Jian Sun. \\\n",
    "    Faster R-CNN: Towards Real-Time Object Detection with \\\n",
    "    Region Proposal Networks. NIPS 2015.\n",
    "    Args:\n",
    "        n_sample (int): The number of sampled regions.\n",
    "        pos_ratio (float): Fraction of regions that is labeled as a\n",
    "            foreground.\n",
    "        pos_iou_thresh (float): IoU threshold for a RoI to be considered as a\n",
    "            foreground.\n",
    "        neg_iou_thresh_hi (float): RoI is considered to be the background\n",
    "            if IoU is in\n",
    "            [:obj:`neg_iou_thresh_hi`, :obj:`neg_iou_thresh_hi`).\n",
    "        neg_iou_thresh_lo (float): See above.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_sample=128,\n",
    "                 pos_ratio=0.25, pos_iou_thresh=0.5,\n",
    "                 neg_iou_thresh_hi=0.5, neg_iou_thresh_lo=0.0\n",
    "                 ):\n",
    "        self.n_sample = n_sample\n",
    "        self.pos_ratio = pos_ratio\n",
    "        self.pos_iou_thresh = pos_iou_thresh\n",
    "        self.neg_iou_thresh_hi = neg_iou_thresh_hi\n",
    "        self.neg_iou_thresh_lo = neg_iou_thresh_lo  # NOTE:default 0.1 in py-faster-rcnn\n",
    "\n",
    "    def __call__(self, roi, bbox, label, depth, y_rot,\n",
    "                 loc_normalize_mean=(0., 0., 0., 0.),\n",
    "                 loc_normalize_std=(0.1, 0.1, 0.2, 0.2)):\n",
    "        \"\"\"Assigns ground truth to sampled proposals.\n",
    "        This function samples total of :obj:`self.n_sample` RoIs\n",
    "        from the combination of :obj:`roi` and :obj:`bbox`.\n",
    "        The RoIs are assigned with the ground truth class labels as well as\n",
    "        bounding box offsets and scales to match the ground truth bounding\n",
    "        boxes. As many as :obj:`pos_ratio * self.n_sample` RoIs are\n",
    "        sampled as foregrounds.\n",
    "        Offsets and scales of bounding boxes are calculated using\n",
    "        :func:`model.utils.bbox_tools.bbox2loc`.\n",
    "        Also, types of input arrays and output arrays are same.\n",
    "        Here are notations.\n",
    "        * :math:`S` is the total number of sampled RoIs, which equals \\\n",
    "            :obj:`self.n_sample`.\n",
    "        * :math:`L` is number of object classes possibly including the \\\n",
    "            background.\n",
    "        Args:\n",
    "            roi (array): Region of Interests (RoIs) from which we sample.\n",
    "                Its shape is :math:`(R, 4)`\n",
    "            bbox (array): The coordinates of ground truth bounding boxes.\n",
    "                Its shape is :math:`(R', 4)`.\n",
    "            label (array): Ground truth bounding box labels. Its shape\n",
    "                is :math:`(R',)`. Its range is :math:`[0, L - 1]`, where\n",
    "                :math:`L` is the number of foreground classes.\n",
    "            depth (array): Ground truth depth labels. Its shape\n",
    "                is :math:`(R',)`. Its range is :math:`[0, 1]`, where\n",
    "                :1 stands for longest length 70m.\n",
    "            y_rot (array): Ground truth rots see in Bird Eye View labels. Its shape\n",
    "                is :math:`(R',)`. Its range is :math:`[-pi, pi]`\n",
    "            loc_normalize_mean (tuple of four floats): Mean values to normalize\n",
    "                coordinates of bouding boxes.\n",
    "            loc_normalize_std (tupler of four floats): Standard deviation of\n",
    "                the coordinates of bounding boxes.\n",
    "        Returns:\n",
    "            (array, array, array):\n",
    "            * **sample_roi**: Regions of interests that are sampled. \\\n",
    "                Its shape is :math:`(S, 4)`.\n",
    "            * **gt_roi_loc**: Offsets and scales to match \\\n",
    "                the sampled RoIs to the ground truth bounding boxes. \\\n",
    "                Its shape is :math:`(S, 4)`.\n",
    "            * **gt_roi_label**: Labels assigned to sampled RoIs. Its shape is \\\n",
    "                :math:`(S,)`. Its range is :math:`[0, L]`. The label with \\\n",
    "                value 0 is the background.\n",
    "            * **gt_roi_depth**: Labels assigned to sampled RoIs. Its shape is \\\n",
    "                :math:`(S,)`. Its range is :math:`[0, 1]`.\n",
    "            * **gt_roi_y_rots**: Labels assigned to sampled RoIs. Its shape is \\\n",
    "                :math:`(S,)`. Its range is :math:`[-pi, pi]`.\n",
    "        \"\"\"\n",
    "        n_bbox, _ = bbox.shape\n",
    "\n",
    "        roi = np.concatenate((roi, bbox), axis=0)\n",
    "\n",
    "        pos_roi_per_image = np.round(self.n_sample * self.pos_ratio)\n",
    "        iou = bbox_iou(roi, bbox)\n",
    "        gt_assignment = iou.argmax(axis=1)\n",
    "        max_iou = iou.max(axis=1)\n",
    "        # Offset range of classes from [0, n_fg_class - 1] to [1, n_fg_class].\n",
    "        # The label with value 0 is the background.\n",
    "        gt_roi_label = label[gt_assignment] + 1\n",
    "        gt_roi_depth = depth[gt_assignment]\n",
    "        gt_roi_y_rot = y_rot[gt_assignment]\n",
    "        # Select foreground RoIs as those with >= pos_iou_thresh IoU.\n",
    "        pos_index = np.where(max_iou >= self.pos_iou_thresh)[0]\n",
    "        pos_roi_per_this_image = int(min(pos_roi_per_image, pos_index.size))\n",
    "        if pos_index.size > 0:\n",
    "            pos_index = np.random.choice(\n",
    "                pos_index, size=pos_roi_per_this_image, replace=False)\n",
    "\n",
    "        # Select background RoIs as those within\n",
    "        # [neg_iou_thresh_lo, neg_iou_thresh_hi).\n",
    "        neg_index = np.where((max_iou < self.neg_iou_thresh_hi) &\n",
    "                             (max_iou >= self.neg_iou_thresh_lo))[0]\n",
    "        neg_roi_per_this_image = self.n_sample - pos_roi_per_this_image\n",
    "        neg_roi_per_this_image = int(min(neg_roi_per_this_image,\n",
    "                                         neg_index.size))\n",
    "        if neg_index.size > 0:\n",
    "            neg_index = np.random.choice(\n",
    "                neg_index, size=neg_roi_per_this_image, replace=False)\n",
    "\n",
    "        # The indices that we're selecting (both positive and negative).\n",
    "        keep_index = np.append(pos_index, neg_index)\n",
    "        gt_roi_label = gt_roi_label[keep_index]\n",
    "        gt_roi_depth = gt_roi_depth[keep_index]\n",
    "        gt_roi_y_rot = gt_roi_y_rot[keep_index]\n",
    "        gt_roi_label[pos_roi_per_this_image:] = 0  # negative labels --> 0\n",
    "        sample_roi = roi[keep_index]\n",
    "\n",
    "        # Compute offsets and scales to match sampled RoIs to the GTs.\n",
    "        gt_roi_loc = bbox2loc(sample_roi, bbox[gt_assignment[keep_index]])\n",
    "        gt_roi_loc = ((gt_roi_loc - np.array(loc_normalize_mean, np.float32)\n",
    "                       ) / np.array(loc_normalize_std, np.float32))\n",
    "\n",
    "        return sample_roi, gt_roi_loc, gt_roi_label, gt_roi_depth, gt_roi_y_rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-a55d6241e360>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-a55d6241e360>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    roi = [[   2.3864822  840.79895     79.58607   1060.9557   ]\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scn",
   "language": "python",
   "name": "scn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
